{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e0d87a0-1186-4c43-9d7b-664c8b697c32",
   "metadata": {},
   "source": [
    "# Data Engineer's basic tasks\n",
    "\n",
    "Here, I have completed several basic steps of the everyday Data Engineer's life and provided comments on my own thoughts regarding the execution methods, my logic, and the libraries I've chosen. I enjoyed working on this task and made every effort to explain my way of thinking. I hope we can find a connection. In any case, I am ready to answer all your questions and provide a more detailed explanation of my solution.\n",
    "\n",
    "**So, let's get started!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e9e707-c84f-4d49-b83a-e5488baaf419",
   "metadata": {},
   "source": [
    "## 1. Getting data from an API\n",
    "\n",
    "I divided the execution of this task into two functions for logical reasons. The first function ___get_data_from_source___ connects to the API and retrieve data. The second function ___store_data___ saves the obtained data into a JSON file, as specified in the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877602a1-fa56-43c9-988f-3f24f8b2f067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_data_from_source(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return data\n",
    "\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        raise http_err\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7708ef02-aa8d-4623-98fd-deb14dd2f80a",
   "metadata": {},
   "source": [
    "This is how the function looks when connecting to a real API.   \n",
    "- I used a ___try-except___ block to prevent the code from terminating in case of an error and to capture the error for analysis and code improvement, depending on the specific behavior of the API.  \n",
    "- The line ___'response.raise_for_status()'___ precisely checks the server response status and captures the 'requests.exceptions.HTTPError' exception, which contains information about the error code and message.  \n",
    "- I used ___requests___ library because it provides a simple and convenient way to make HTTP requests to web resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324d053c-b23f-4da1-afdd-b975483358c0",
   "metadata": {},
   "source": [
    "Since we don't have a working server in this specific case, I simply read data from an existing JSON file and will write it to a separate JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38987cdb-8fca-4de1-9663-4a31b3fd2b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_data_from_source(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as input_file:\n",
    "            data = json.load(input_file)\n",
    "        return data\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f'File not found: {filename}')\n",
    "        return None\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f'JSON decoding error: {str(e)}')\n",
    "        return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'FAIL while get_data_from_source: {str(e)}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066dd692-b3ff-472c-a144-defa3ab011a9",
   "metadata": {},
   "source": [
    "- Here, I used a ___\"with\"___ of context manager to work with the file, which automatically closes the file and releases memory when the function execution is completed.  \n",
    "- The parameter ___'r'___ signifies that we are opening the file for reading only.  \n",
    "- Additionally, I have handled certain ___exceptions___ that may occur if the file is not found or if the data in it doesn't conform to the JSON format.\n",
    "- Also ___json___ library allows working with JSON files as python objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d365b9-097b-4122-bfe1-27393f6cc3a1",
   "metadata": {},
   "source": [
    "I used arguments in both functions to allow them work with different sourses, not only with specified ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8181a9-b34d-469d-9781-69b5e15da869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_data(data):\n",
    "    try:\n",
    "        with open('data.json', 'a') as outfile:\n",
    "            json.dump(data, outfile, indent=4)\n",
    "    except Exception as e:\n",
    "        print(f\"FAIL while store_data: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ee1574-331c-4568-8646-1f9ba27688e5",
   "metadata": {},
   "source": [
    "This function takes data and saves it to a separate file.  \n",
    "\n",
    "- I used the ___'a'___ argument to append data to the file with each function call, preserving the previous data. If we need to overwrite the data in the file, we can use the ___'w'___ parameter. The file will also be created if it does not exist beforehand.\n",
    "- Part of ___'indent=4'___ helps make the data prettier and more readable by adding 4 spaces.\n",
    "- To track the progress of the program, I use regular ___prints___, but for more high-quality, convenient, and reliable tracking, ___logging___ can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39433e1-8908-46e2-a38d-cf092ecf715c",
   "metadata": {},
   "source": [
    "## 2. Data clean-up\n",
    "\n",
    "Data cleaning is the process of identifying and correcting or removing errors, inconsistencies, and inaccuracies in data sets. It involves checking data for completeness, removing duplicate entries, dealing with missing data, standardizing data formats, and correcting data values that are out of range or invalid.\n",
    "\n",
    "- Accurate data is essential for making informed decisions: If the data is incorrect, any insights or conclusions drawn from it may be flawed.\n",
    "- Data cleaning can help identify and prevent errors early on: This can save time and resources by avoiding costly mistakes downstream.\n",
    "- Data cleaning can improve the quality of data: By removing errors and inconsistencies, data becomes more reliable and trustworthy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c250b4b-fbc3-4b43-8895-3cb8cd033002",
   "metadata": {},
   "source": [
    "##### In this specific case, we have a small amount of data, so data cleanliness analysis can be easily done manually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448b727c-5469-4193-8f46-50be9289dec9",
   "metadata": {},
   "source": [
    "At first glance, the __'Quantity (£)'__ column caught my eye for two reasons - it has the ___currency name___ in the values and also contains ___negative___ values. Clearly, for financial analysis, the data type should be numeric, and the commonly used data type for this purpose is 'float' with two decimal places. Therefore, we should _remove_ the currency mention and _convert_ type.  \n",
    "As for the negative values, they deserve special attention. Initially, we might consider simply deleting this row because in the context of electricity consumption, negative values imply 'energy generation,' and we assume that the Glasgow office is not involved in energy production. However, upon closer examination, I notice that it pertains to only one day, unlike the other data, which represents reports for specific months. Furthermore, this row shares a similar account number with the one above it, where the office name and location match, but with the addition of _'-re'_, which could indicate a debt or a case where the company initially reserved more electricity than it used, for instance. So, I would definitely _keep_ this row, although it could also be logically _combined_ with the one indicating the period to which it belongs. I would discuss this aspect with a colleague as the choice depends on the goals of further data analysis.    \n",
    "I also noticed the outlier values because the value of 5000 is significantly different from the average. I would discuss this with a more experienced colleague, but I personally find it quite logical that energy consumption and its cost increase in November as the daylight hours and temperature decrease compared to October. Although the values in November are twice as high as in December, this can be explained by the greater number of working days in the office in November compared to December and its calendar holidays. And even when comparing this value to the value for the same period but for a different office (Spain), it can be explained by geographical weather data and a significant _difference in the number of office employees_.\n",
    "\n",
    "Additionally, I observe that __'Bill number'__ names follow different naming conventions for different offices. In my current solution, I did not modify this column as I believe that the naming logic is entirely unique to each office location and does not repeat. However, this can certainly be discussed with a colleague, as standardized bill _numbers_ might be necessary for analysis.\n",
    "\n",
    "I also noticed variations in categorical names in the __'Country'__ column for the same location. Therefore, in my solution, I _replace_ 'United Kingdom' with 'GB'.\n",
    "\n",
    "The values in __'Time Period'__ column follow the same logic, but to work with dates, it need to _be converted_ to a data type appropriate for dates.\n",
    "\n",
    "The __'Supplier'__ and __'Tariff Name'__ columns _do not raise any questions_ for me.\n",
    "\n",
    "However, regarding the values in the __'Price per kWh'__ column, I would make some changes - it's necessary to _remove_ the currency mention, _convert_ the column to a numeric 'float' data type, and for convenience, _convert_ 'p' to 'GBP' to have consistent numerical scales for each financial column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d437fe92-12eb-43c3-8ef6-e5976bb93b5a",
   "metadata": {},
   "source": [
    "##### However, in a real-world scenario with a large volume of data, we should automate the process to speed up work and save human resources.\n",
    "The initial steps involve reading data from a file and displaying a few data rows for human inspection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4845a0-ac7f-4a42-8316-b6fe844b1b1c",
   "metadata": {},
   "source": [
    "(___Pandas___ library is a perfect fit for this task as it allows easy data reading from various sources (in our case, a CSV file) and offers a plethora of methods for filtering, replacing, transforming, and removing data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fda4ef3f-da8b-4b10-8385-d2c816a7acbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('utilities.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1256ab6c-2fcb-4de2-afdb-f7e1914832e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facility Name</th>\n",
       "      <th>Bill number</th>\n",
       "      <th>Quantity (£)</th>\n",
       "      <th>Location</th>\n",
       "      <th>Country</th>\n",
       "      <th>Time Period</th>\n",
       "      <th>Supplier</th>\n",
       "      <th>Tariff Name</th>\n",
       "      <th>Price per kWh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HQ</td>\n",
       "      <td>hq-001</td>\n",
       "      <td>1000</td>\n",
       "      <td>Headquarters</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Oct-1 - Oct-31 2021</td>\n",
       "      <td>EnergyCorp</td>\n",
       "      <td>Renewable 100</td>\n",
       "      <td>25p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HQ</td>\n",
       "      <td>hq-002</td>\n",
       "      <td>5000</td>\n",
       "      <td>Headquarters</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Nov-1 - Nov-30 2021</td>\n",
       "      <td>EnergyCorp</td>\n",
       "      <td>Renewable 100</td>\n",
       "      <td>25p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HQ</td>\n",
       "      <td>hq-003</td>\n",
       "      <td>2500</td>\n",
       "      <td>Headquatrers</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Dec-01 - Dec-31 2021</td>\n",
       "      <td>EnergyCorp</td>\n",
       "      <td>Renewable 100</td>\n",
       "      <td>25p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Office Scotland</td>\n",
       "      <td>1235</td>\n",
       "      <td>900</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>GB</td>\n",
       "      <td>Nov-1 - Nov-30 2021</td>\n",
       "      <td>EnergyCorp</td>\n",
       "      <td>coal-only</td>\n",
       "      <td>16p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Office Scotland</td>\n",
       "      <td>0815</td>\n",
       "      <td>1000</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>GB</td>\n",
       "      <td>Dec-1 - Dec-31 2021</td>\n",
       "      <td>PowerSupply</td>\n",
       "      <td>PowerSupply Budget</td>\n",
       "      <td>18p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Office Scotland</td>\n",
       "      <td>0815-re</td>\n",
       "      <td>-200</td>\n",
       "      <td>Glasgow</td>\n",
       "      <td>GB</td>\n",
       "      <td>Dec-29 - Dec-29 2021</td>\n",
       "      <td>PowerSupply</td>\n",
       "      <td>PowerSupply Budget</td>\n",
       "      <td>18p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Office Spain</td>\n",
       "      <td>December</td>\n",
       "      <td>1000 GBP</td>\n",
       "      <td>Spain Office</td>\n",
       "      <td>ESP</td>\n",
       "      <td>Nov-1 - Nov-30 2021</td>\n",
       "      <td>EnergyCorp</td>\n",
       "      <td>coal-only</td>\n",
       "      <td>16p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Facility Name Bill number Quantity (£)      Location         Country  \\\n",
       "0               HQ      hq-001         1000  Headquarters  United Kingdom   \n",
       "1               HQ      hq-002         5000  Headquarters  United Kingdom   \n",
       "2               HQ      hq-003         2500  Headquatrers  United Kingdom   \n",
       "3  Office Scotland        1235          900       Glasgow              GB   \n",
       "4  Office Scotland        0815         1000       Glasgow              GB   \n",
       "5  Office Scotland     0815-re         -200       Glasgow              GB   \n",
       "6     Office Spain    December     1000 GBP  Spain Office             ESP   \n",
       "\n",
       "            Time Period     Supplier         Tariff Name Price per kWh  \n",
       "0   Oct-1 - Oct-31 2021   EnergyCorp       Renewable 100           25p  \n",
       "1   Nov-1 - Nov-30 2021   EnergyCorp       Renewable 100           25p  \n",
       "2  Dec-01 - Dec-31 2021   EnergyCorp      Renewable 100            25p  \n",
       "3   Nov-1 - Nov-30 2021   EnergyCorp           coal-only           16p  \n",
       "4   Dec-1 - Dec-31 2021  PowerSupply  PowerSupply Budget           18p  \n",
       "5  Dec-29 - Dec-29 2021  PowerSupply  PowerSupply Budget           18p  \n",
       "6   Nov-1 - Nov-30 2021   EnergyCorp           coal-only           16p  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10) #to print first 10 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6210633-a469-40b2-970e-c2a8476d60d0",
   "metadata": {},
   "source": [
    "At this stage, in addition to the issues I've already described above, I've also noticed extra spaces that need to be removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb45d98c-4465-4deb-835b-b9b9f664a7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.map(lambda x: x.rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2057cd74-bab4-48e7-a859-951d2918a5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7 entries, 0 to 6\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Facility Name  7 non-null      object\n",
      " 1   Bill number    7 non-null      object\n",
      " 2   Quantity (£)   7 non-null      object\n",
      " 3   Location       7 non-null      object\n",
      " 4   Country        7 non-null      object\n",
      " 5   Time Period    7 non-null      object\n",
      " 6   Supplier       7 non-null      object\n",
      " 7   Tariff Name    7 non-null      object\n",
      " 8   Price per kWh  7 non-null      object\n",
      "dtypes: object(9)\n",
      "memory usage: 632.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ff7dbc-a06b-45d1-9071-9854b03b3eec",
   "metadata": {},
   "source": [
    "Analyzing this output helps determine which columns contain non-null values and their data types. Here, we can see that all columns in our data are filled, which meets data cleanliness standards. We also observe the data types; all columns have the 'object' data type, typically used for textual data. However, considering the context, columns like 'Quantity (£)' and 'Price per kWh' should be converted to 'float', while 'Time Period' should be converted to 'date'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f1bd6c-8ddf-440b-9f42-d43adadcfed2",
   "metadata": {},
   "source": [
    "Let's start with the 'Quantity (£)' column.   \n",
    "I use a function that converts the column to a numerical float type. I specify 'errors='raise'' to catch any errors that might occur. (Assuming I haven't seen the complete data, and there don't appear to be any obvious issues with the column in the initial sample.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "460c8274-87b5-4892-95a8-6f3cc2179b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Quantity (£)'] = pd.to_numeric(df['Quantity (£)'], errors='raise')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d13ccb6-9367-4505-8228-adcc22c63fea",
   "metadata": {},
   "source": [
    "We see that the error arises from the sixth row, where the value is '1000 GBP.' Let's remove this currency mention from all rows that 'might still exist' in our data using simple regular expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41ae59fe-0871-475c-a98a-37e447eab95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Quantity (£)'] = df['Quantity (£)'].str.replace(' GBP', '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542ce6da-115a-44d8-88ba-2a3633518df2",
   "metadata": {},
   "source": [
    "Now our data can be converted to another data type again. If I encountered another error, for example, another currency mention, I would handle it similarly or take steps based on the specific situation. We follow a similar approach with the column 'Price per kWh'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1507442-f258-4e53-a9db-6b36aab408d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Price per kWh'] = df['Price per kWh'].str.replace('p', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7f97bf6-8173-4e83-aff6-87957dcf7148",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Price per kWh'] = pd.to_numeric(df['Price per kWh'], errors='raise')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc15fafd-23a0-4fd5-9400-3ffcfd86a380",
   "metadata": {},
   "source": [
    "Additionally, as part of working with this column, I convert pennies to British pounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63e72a89-aceb-474a-8f78-2375c9304d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Price per kWh'] = df['Price per kWh'] / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a4d8b3-0f1b-4023-bbe2-85a0ac767d1d",
   "metadata": {},
   "source": [
    "When it comes to the 'Time Period', I split a single column into two - one for the start date and the other for the end date of the period. Since our source data has a complex structure, I use regular expressions for precise date extraction, involving three letters for the month, one or two digits for the day, and four digits for the year. The extracted data is distributed into auxiliary columns, which are later removed. Then, I use the ___'pd.to_datetime'___ method to convert the format into the expected date format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9398b8b-1c36-4a8d-ad5c-5710869b3fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_pattern = r'(\\w{3}-\\d{1,2}) - (\\w{3}-\\d{1,2}) (\\d{4})'\n",
    "df[['Start', 'End', 'Year']] = df['Time Period'].str.extract(date_pattern)\n",
    "\n",
    "df['Start Date'] = pd.to_datetime(df['Start'] + ' ' + df['Year'], format='%b-%d %Y')\n",
    "df['End Date'] = pd.to_datetime(df['End'] + ' ' + df['Year'], format='%b-%d %Y')\n",
    "\n",
    "df = df.drop(columns=['Time Period', 'Start', 'End', 'Year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962eb978-bce0-43df-8a8e-532983da9c11",
   "metadata": {},
   "source": [
    "We it is needed to check the boundary values. Let's do this using the 'Quantity (£)' column as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b98eb2f5-93e2-4ca4-a71b-7436a2bc7b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "-200\n"
     ]
    }
   ],
   "source": [
    "print(df['Quantity (£)'].max())\n",
    "print(df['Quantity (£)'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34f7185-c113-4161-b47a-d3fae449eb34",
   "metadata": {},
   "source": [
    "We've already discussed boundary values earlier. Now, let's check categorical values. I do this using the 'Country' column as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23b95d2d-6ca8-4119-aafb-0bc7864cd452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country\n",
       "United Kingdom    3\n",
       "GB                3\n",
       "ESP               1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050d935e-047e-43e5-a420-76f4061ce0b1",
   "metadata": {},
   "source": [
    "I standardize different variations of names for the same semantic category. Since it is used an abbreviation for The Kingdom of Spain, I also choose 'GB' for The United Kingdom of Great Britain and Northern Ireland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41e19a0c-43f5-4e94-9c8c-e3c914443803",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Country'] = df['Country'].str.replace('United Kingdom', 'GB', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d12964-257c-4a10-b980-817645d02997",
   "metadata": {},
   "source": [
    "Also, if we check 'Location' column, we notice misspelling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2580739e-dc4a-490b-986a-cbc4f20d6837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location\n",
       "Headquarters    3\n",
       "Glasgow         3\n",
       "Spain Office    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b418181-5f38-4d20-911c-15909982382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Location'] = df['Location'].str.replace('Headquatrers', 'Headquarters', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d777519a-fa7f-463a-80c1-b7b272f128e4",
   "metadata": {},
   "source": [
    "Now it's time to save the cleaned data into a new file without including the index column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a734fc8f-d54b-4513-ad5a-d125fa18da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cleaned_utilities.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0342f4f6-5248-4b5c-9d5a-f84415a8d5f0",
   "metadata": {},
   "source": [
    "## 3. Data wrangling\n",
    "\n",
    "Considering both the columns from the specification and the clean date columns I obtained in the previous step, I would design the data as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55198c6f-ed74-4769-ad60-348448034236",
   "metadata": {},
   "source": [
    "![db_design](db_design.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1013a91-6874-400d-bffa-3e96b3642771",
   "metadata": {},
   "source": [
    "I attempted to logically combine certain columns and isolate others that are independent of each other. All IDs in my database design are of integer type and automatically increment when new rows are added. 'Tariff' is a renamed column from 'Price per kWh.' To calculate the 'Spend' column, I divided 'Quantity' by 'Tariff'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfefeb3-19de-4030-9693-3cb4e2108b49",
   "metadata": {},
   "source": [
    "Here is the pandas code for turning data into specification format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b708253-fe34-4d60-92a5-56b050a0bd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_utilities.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ce71fa-10c3-4a79-8b93-ee057302da7c",
   "metadata": {},
   "source": [
    "Rename columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "579b1d6d-029b-4fd4-8ad0-cd7fae998e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Facility Name': 'Facility_name',\n",
    "                   'Bill number': 'Bill_name',\n",
    "                   'Quantity (£)': 'Quantity',\n",
    "                   'Location': 'Location',\n",
    "                   'Country': 'Country',\n",
    "                   'Supplier': 'Supplier',\n",
    "                   'Tariff Name': 'Tariff_name',\n",
    "                   'Price per kWh': 'Tariff',\n",
    "                   'Start Date': 'Start_date',\n",
    "                   'End Date': 'End_date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49929620-d6ea-4fa1-bbe2-2dbaddf2797d",
   "metadata": {},
   "source": [
    "Add new necessary columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94edb94a-f786-43d3-800f-c13bd8ce166a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Currency'] = 'GBP'\n",
    "df['Unit'] = 'kWh'\n",
    "df['Spend'] = df['Quantity'] / df['Tariff']\n",
    "df['Spend'] = df['Spend'].round(2)  #round to second decimal\n",
    "\n",
    "df['Facility_ID'] = df.groupby('Facility_name').ngroup() + 1\n",
    "df['Utility_ID'] = df.groupby('Bill_name').ngroup() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d730154c-53f4-437c-8fd4-0fec3c4acfa9",
   "metadata": {},
   "source": [
    "Create result file for specification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57cf6d0b-d265-454d-89ea-302f67915fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_export = ['Facility_ID', 'Utility_ID', 'Tariff', 'Quantity', 'Unit', 'Spend', 'Currency', 'Start_date', 'End_date']\n",
    "result_df = df[columns_to_export]\n",
    "result_df.to_csv('output_report.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee7609d-2937-4e3f-96af-be0a5ace0199",
   "metadata": {},
   "source": [
    "Take a glance on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba5dc3fa-d277-4de9-bfaa-9b5b4a8e7319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facility_ID</th>\n",
       "      <th>Utility_ID</th>\n",
       "      <th>Tariff</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Spend</th>\n",
       "      <th>Currency</th>\n",
       "      <th>Start_date</th>\n",
       "      <th>End_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1000</td>\n",
       "      <td>kWh</td>\n",
       "      <td>4000.00</td>\n",
       "      <td>GBP</td>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>2021-10-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.25</td>\n",
       "      <td>5000</td>\n",
       "      <td>kWh</td>\n",
       "      <td>20000.00</td>\n",
       "      <td>GBP</td>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>2021-11-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2500</td>\n",
       "      <td>kWh</td>\n",
       "      <td>10000.00</td>\n",
       "      <td>GBP</td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>2021-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.16</td>\n",
       "      <td>900</td>\n",
       "      <td>kWh</td>\n",
       "      <td>5625.00</td>\n",
       "      <td>GBP</td>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>2021-11-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1000</td>\n",
       "      <td>kWh</td>\n",
       "      <td>5555.56</td>\n",
       "      <td>GBP</td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>2021-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-200</td>\n",
       "      <td>kWh</td>\n",
       "      <td>-1111.11</td>\n",
       "      <td>GBP</td>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>2021-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1000</td>\n",
       "      <td>kWh</td>\n",
       "      <td>6250.00</td>\n",
       "      <td>GBP</td>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>2021-11-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Facility_ID  Utility_ID  Tariff  Quantity Unit     Spend Currency  \\\n",
       "0            1           5    0.25      1000  kWh   4000.00      GBP   \n",
       "1            1           6    0.25      5000  kWh  20000.00      GBP   \n",
       "2            1           7    0.25      2500  kWh  10000.00      GBP   \n",
       "3            2           3    0.16       900  kWh   5625.00      GBP   \n",
       "4            2           1    0.18      1000  kWh   5555.56      GBP   \n",
       "5            2           2    0.18      -200  kWh  -1111.11      GBP   \n",
       "6            3           4    0.16      1000  kWh   6250.00      GBP   \n",
       "\n",
       "   Start_date    End_date  \n",
       "0  2021-10-01  2021-10-31  \n",
       "1  2021-11-01  2021-11-30  \n",
       "2  2021-12-01  2021-12-31  \n",
       "3  2021-11-01  2021-11-30  \n",
       "4  2021-12-01  2021-12-31  \n",
       "5  2021-12-29  2021-12-29  \n",
       "6  2021-11-01  2021-11-30  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937ed88d-2c3a-4d80-97f8-54a77619efc7",
   "metadata": {},
   "source": [
    "When I generated the resulting data, I had some questions about the 'Spend' column, where I calculated energy expenses. The values seemed controversial to me. Therefore, I would like to consult with a colleague regarding my decision.    \n",
    "Additionally, there is another scenario in which the 'Quantity (£)' column was initially named incorrectly and represented not the cost of electricity but its consumption in kWh. In that case, a different approach would be needed for the value '1000 GBP'. And 'Spend' column would be the result of multiplying the 'Tariff' by 'Quantity' columns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
